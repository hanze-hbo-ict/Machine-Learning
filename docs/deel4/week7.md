# Week 7: Recurrente neurale netwerken

## Onderwerpen

* Dimensionaliteitsreductie
    * Projectie en Manifold Learning
    * PCA
* Recurrente neurale netwerken (RNN's)
* RNN's met geheugen (LSTM, GRU)

## College-sheets

Na afloop van het hoorcollege komen hier de gebruikte slides en notebooks beschikbaar.
<!--
* [Hier](../lectures/wk7/7_8.taalmodellen.pptx) vindt u de presentatie die in het college gebruikt is.
* En [hier](../lectures/wk7/livecoding/PCA.ipynb) de Notebook over Principal Components Analysis (PCA).
* En [hier](../lectures/wk7/livecoding/Text%20Generation%20with%20RNN.ipynb) de Notebook waarin we geprobeerd hebben een science fiction-roman te schrijven op basis van _character prediction_ met een RNN. **NB**: dat er naast de vectorisatie ook een Embedding-laag in het definitieve model zit, is het correct en nodig om de als int's gecodeerde karakters om te zetten in vectoren van floats die (beter) door het netwerk verwerkt kunnen worden.
-->

## Lezen

* GÃ©ron: hoofdstuk 15 en 16
