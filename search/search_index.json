{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welkom bij Machine Learning","text":"<p>Hier vindt u de stof (per week) en de opgaven (per blok van twee weken).</p>"},{"location":"index.html#deel-1","title":"Deel 1","text":"<ul> <li>Week 1</li> <li>Week 2</li> <li>Inlevermoment</li> </ul>"},{"location":"index.html#deel-2","title":"Deel 2","text":"<ul> <li>Week 3</li> <li>Week 4</li> <li>Inlevermoment</li> </ul>"},{"location":"index.html#deel-3","title":"Deel 3","text":"<ul> <li>Week 5</li> <li>Week 6</li> <li>Inlevermoment</li> </ul>"},{"location":"index.html#deel-4","title":"Deel 4","text":"<ul> <li>Week 7</li> <li>Week 8</li> <li>Inlevermoment</li> </ul>"},{"location":"files/Introductie%20Pandas.html","title":"Introductie Pandas","text":"<pre><code>import pandas as pd\npd.Series?\n</code></pre> <pre><code>animals = ['Tiger','Bear','Moose']\npd.Series(animals)\n</code></pre> <pre>\n<code>0    Tiger\n1     Bear\n2    Moose\ndtype: object</code>\n</pre> <pre><code>numbers = [3,1,4]\npd.Series(numbers)\n</code></pre> <pre>\n<code>0    3\n1    1\n2    4\ndtype: int64</code>\n</pre> <pre><code>animals = ['Tiger','Bear', None]\npd.Series(animals)\n</code></pre> <pre>\n<code>0    Tiger\n1     Bear\n2     None\ndtype: object</code>\n</pre> <pre><code>numbers = [3, 1, None]\npd.Series(numbers)\n</code></pre> <pre>\n<code>RangeIndex(start=0, stop=3, step=1)</code>\n</pre> <pre><code>import numpy as np\nnp.nan == None\n</code></pre> <pre>\n<code>False</code>\n</pre> <pre><code>if(np.nan):\n    print ('check')\n</code></pre> <pre>\n<code>check\n</code>\n</pre> <pre><code>np.nan == np.nan\n</code></pre> <pre>\n<code>False</code>\n</pre> <pre><code>np.isnan(np.nan)\n</code></pre> <pre>\n<code>True</code>\n</pre> <pre><code>numbers = [3,1,4,'Bear', None]\npd.Series(numbers)\n</code></pre> <pre>\n<code>0       3\n1       1\n2       4\n3    Bear\n4    None\ndtype: object</code>\n</pre> <pre><code>np.isnan('hoi')\n</code></pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nInput In [18], in &lt;cell line: 1&gt;()\n----&gt; 1 np.isnan('hoi')\n\nTypeError: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''</pre> <pre><code>sports = {'Achery':'Bhutan',\n         'Golf':'Scotland',\n         'Sumo':'Japan',\n         'Taekwondo':'South Korea'}\ns = pd.Series(sports)\ns\n</code></pre> <pre>\n<code>Achery            Bhutan\nGolf            Scotland\nSumo               Japan\nTaekwondo    South Korea\ndtype: object</code>\n</pre> <pre><code>s.index\n</code></pre> <pre>\n<code>Index(['Achery', 'Golf', 'Sumo', 'Taekwondo'], dtype='object')</code>\n</pre> <pre><code>pd.Series(['Tiger','Bear','Moose'], index=['India','India', 1]).index\n</code></pre> <pre>\n<code>Index(['India', 'India', 1], dtype='object')</code>\n</pre> <pre><code>sports = {'Achery':'Bhutan',\n         'Golf':'Scotland',\n         'Sumo':'Japan',\n         'Taekwondo':'South Korea'}\ns = pd.Series(sports, index=['Golf','Sumo','Hockey'])\ns\n</code></pre> <pre>\n<code>Golf      Scotland\nSumo         Japan\nHockey         NaN\ndtype: object</code>\n</pre> <pre><code>sports = {'Achery':'Bhutan',\n         'Golf':'Scotland',\n         'Sumo':'Japan',\n         'Taekwondo':'South Korea'}\ns = pd.Series(sports)\ns\n</code></pre> <pre>\n<code>Achery            Bhutan\nGolf            Scotland\nSumo               Japan\nTaekwondo    South Korea\ndtype: object</code>\n</pre> <pre><code>s.iloc[ [1,3] ]\n</code></pre> <pre>\n<code>Golf            Scotland\nTaekwondo    South Korea\ndtype: object</code>\n</pre> <pre><code>s.iloc[ 0:3 ]\n</code></pre> <pre>\n<code>Achery      Bhutan\nGolf      Scotland\nSumo         Japan\ndtype: object</code>\n</pre> <pre><code>s.loc[ ['Achery','Sumo'] ]\n</code></pre> <pre>\n<code>Achery    Bhutan\nSumo       Japan\ndtype: object</code>\n</pre> <pre><code>s = pd.Series( data=[100, 120, 101, 3])\ns\n</code></pre> <pre>\n<code>0    100\n1    120\n2    101\n3      3\ndtype: int64</code>\n</pre> <pre><code>%%timeit\nsum(s)\n</code></pre> <pre>\n<code>940 ns \u00b1 5.52 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n</code>\n</pre> <pre><code>%%timeit\ntot = 0\nfor i in s:\n    tot += i\n\ntot\n</code></pre> <pre>\n<code>997 ns \u00b1 9.23 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n</code>\n</pre> <pre><code>%%timeit\nimport numpy as np\ntot = np.sum(s)\ntot\n</code></pre> <pre>\n<code>16.4 \u00b5s \u00b1 100 ns per loop (mean \u00b1 std. dev. of 7 runs, 100,000 loops each)\n</code>\n</pre> <pre><code>s = pd.Series(np.random.randint(0,1000,100))\ns.head()\n</code></pre> <pre>\n<code>0    964\n1    374\n2    543\n3    571\n4    908\ndtype: int64</code>\n</pre> <pre><code>len(s)\n</code></pre> <pre>\n<code>10000</code>\n</pre> <pre><code>%%timeit -n 100\ntot = 0\nfor x in s:\n    tot += x\n\n    tot\n</code></pre> <pre>\n<code>700 \u00b5s \u00b1 142 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code>\n</pre> <pre><code>%%timeit -n 100\ntot = np.sum(s)\ntot\n</code></pre> <pre>\n<code>The slowest run took 4.08 times longer than the fastest. This could mean that an intermediate result is being cached.\n60.7 \u00b5s \u00b1 23.1 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code>\n</pre> <pre><code>original_sports = pd.Series({'Archery': 'Bhutan',\n                             'Golf': 'Scotland',\n                             'Sumo': 'Japan',\n                             'Taekwondo': 'South Korea'})\ncricket_loving_countries = pd.Series(['Australia',\n                                      'Barbados',\n                                      'Pakistan',\n                                      'England'], \n                                   index=['Cricket',\n                                          'Cricket',\n                                          'Cricket',\n                                          'Cricket'])\nall_countries = original_sports.append(cricket_loving_countries)\nall_countries\n</code></pre> <pre>\n<code>/var/folders/sh/djdw6j_j1zbfpbcf7k2z77rc0000gp/T/ipykernel_22805/2265387507.py:13: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  all_countries = original_sports.append(cricket_loving_countries)\n</code>\n</pre> <pre>\n<code>Archery           Bhutan\nGolf            Scotland\nSumo               Japan\nTaekwondo    South Korea\nCricket        Australia\nCricket         Barbados\nCricket         Pakistan\nCricket          England\ndtype: object</code>\n</pre> <pre><code>all_countries.loc['Cricket']\n</code></pre> <pre>\n<code>Cricket    Australia\nCricket     Barbados\nCricket     Pakistan\nCricket      England\ndtype: object</code>\n</pre> <pre><code>d = {'Archery': 'Bhutan',\n                             'Golf': 'Scotland',\n                             'Sumo': 'Japan',\n                             'Taekwondo': 'South Korea'}\nd['Archery'] = 'Groningen'\nd\n</code></pre> <pre>\n<code>{'Archery': 'Groningen',\n 'Golf': 'Scotland',\n 'Sumo': 'Japan',\n 'Taekwondo': 'South Korea'}</code>\n</pre> <pre><code>purchase_1 = pd.Series({'Name': 'Chris',\n                        'Item Purchased': 'Dog Food',\n                        'Cost': 22.50})\npurchase_2 = pd.Series({'Name': 'Kevyn',\n                        'Item Purchased': 'Kitty Litter',\n                        'Cost': 2.50})\npurchase_3 = pd.Series({'Name': 'Vinod',\n                        'Item Purchased': 'Bird Seed',\n                        'Cost': 5.00})\npurchase_4 = pd.Series({'Name': 'Karel',\n                        'Item Purchased': 'Aston Martin',\n                        'Cost': 97})\n\ndf = pd.DataFrame(data=[purchase_1, purchase_2, purchase_3, purchase_4], index=['Store 1', 'Store 2', 'Store 3', 'Store 4'])\ndf.head()\n</code></pre> Name Item Purchased Cost Store 1 Chris Dog Food 22.5 Store 2 Kevyn Kitty Litter 2.5 Store 3 Vinod Bird Seed 5.0 Store 4 Karel Aston Martin 97.0 <pre><code>df.loc[ ['Store 1', 'Store 3'] ]\n</code></pre> Name Item Purchased Cost Store 1 Chris Dog Food 22.5 Store 3 Vinod Bird Seed 5.0 <pre><code>df.loc['Store 1']['Cost']\n</code></pre> <pre>\n<code>22.5</code>\n</pre> <pre><code>df.T\n</code></pre> Store 1 Store 2 Store 3 Name Chris Kevyn Vinod Item Purchased Dog Food Kitty Litter Bird Seed Cost 22.5 2.5 5.0 <pre><code>df.T.loc['Name']\n</code></pre> <pre>\n<code>Store 1    Chris\nStore 2    Kevyn\nStore 3    Vinod\nName: Name, dtype: object</code>\n</pre> <pre><code>df.shape\n</code></pre> <pre>\n<code>(4, 3)</code>\n</pre> <pre><code>arr = np.array( [[1,2,3], [2,4,6], [2,3,5], [1,3,5]] )\narr\n</code></pre> <pre>\n<code>array([[1, 2, 3],\n       [2, 4, 6],\n       [2, 3, 5],\n       [1, 3, 5]])</code>\n</pre> <pre><code>arr.shape\n</code></pre> <pre>\n<code>(4, 3)</code>\n</pre> <pre><code>arr[0:2, :]\n</code></pre> <pre>\n<code>array([[1, 2, 3],\n       [2, 4, 6]])</code>\n</pre> <pre><code>df.loc[['Store 1','Store 3'], ['Name', 'Cost']]\n</code></pre> Name Cost Store 1 Chris 22.5 Store 3 Vinod 5.0 <pre><code>df.drop('Store 4')\n</code></pre> Name Item Purchased Cost Store 1 Chris Dog Food 22.5 Store 2 Kevyn Kitty Litter 2.5 Store 3 Vinod Bird Seed 5.0 <pre><code>df2 = df.copy()\ndf2.drop('Store 1', inplace=True)\n</code></pre> <pre><code>df2\n</code></pre> Name Item Purchased Cost Store 2 Kevyn Kitty Litter 2.5 Store 3 Vinod Bird Seed 5.0 Store 4 Karel Aston Martin 97.0 <pre><code>df2.drop('Name', inplace=True, axis=1)\n</code></pre> <pre><code>df2\n</code></pre> Item Purchased Cost Store 3 Bird Seed 5.0 Store 4 Aston Martin 97.0 <pre><code>df = pd.read_csv('data/olympics.csv', header=0, skiprows=1)\ndf.head()\n</code></pre> Unnamed: 0 \u2116 Summer 01 ! 02 ! 03 ! Total \u2116 Winter 01 !.1 02 !.1 03 !.1 Total.1 \u2116 Games 01 !.2 02 !.2 03 !.2 Combined total 0 Afghanistan\u00a0(AFG) 13 0 0 2 2 0 0 0 0 0 13 0 0 2 2 1 Algeria\u00a0(ALG) 12 5 2 8 15 3 0 0 0 0 15 5 2 8 15 2 Argentina\u00a0(ARG) 23 18 24 28 70 18 0 0 0 0 41 18 24 28 70 3 Armenia\u00a0(ARM) 5 1 2 9 12 6 0 0 0 0 11 1 2 9 12 4 Australasia\u00a0(ANZ) [ANZ] 2 3 4 5 12 0 0 0 0 0 2 3 4 5 12 <pre><code>df.columns\n</code></pre> <pre>\n<code>Index(['Unnamed: 0', '\u2116 Summer', '01 !', '02 !', '03 !', 'Total', '\u2116 Winter',\n       '01 !.1', '02 !.1', '03 !.1', 'Total.1', '\u2116 Games', '01 !.2', '02 !.2',\n       '03 !.2', 'Combined total'],\n      dtype='object')</code>\n</pre> <pre><code>for col in df.columns:\n    if col[:2]=='01':\n        df.rename(columns={col:'Gold' + col[4:]}, inplace=True)\n    if col[:2]=='02':\n        df.rename(columns={col:'Silver' + col[4:]}, inplace=True)\n    if col[:2]=='03':\n        df.rename(columns={col:'Bronze' + col[4:]}, inplace=True)\n    if col[:1]=='\u2116':\n        df.rename(columns={col:'#' + col[1:]}, inplace=True) \n\ndf.columns\n</code></pre> <pre>\n<code>Index(['Unnamed: 0', '# Summer', 'Gold', 'Silver', 'Bronze', 'Total',\n       '# Winter', 'Gold.1', 'Silver.1', 'Bronze.1', 'Total.1', '# Games',\n       'Gold.2', 'Silver.2', 'Bronze.2', 'Combined total'],\n      dtype='object')</code>\n</pre> <pre><code>l = ['Gold','Silver','Bronze']\n[l[int(x[:2])-1]+x[4:] for x in df.columns if x[:2] in ['01','02','03']]\n</code></pre> <pre>\n<code>[]</code>\n</pre> <pre><code>df\n</code></pre> Unnamed: 0 # Summer Gold Silver Bronze Total # Winter Gold.1 Silver.1 Bronze.1 Total.1 # Games Gold.2 Silver.2 Bronze.2 Combined total 0 Afghanistan\u00a0(AFG) 13 0 0 2 2 0 0 0 0 0 13 0 0 2 2 1 Algeria\u00a0(ALG) 12 5 2 8 15 3 0 0 0 0 15 5 2 8 15 2 Argentina\u00a0(ARG) 23 18 24 28 70 18 0 0 0 0 41 18 24 28 70 3 Armenia\u00a0(ARM) 5 1 2 9 12 6 0 0 0 0 11 1 2 9 12 4 Australasia\u00a0(ANZ) [ANZ] 2 3 4 5 12 0 0 0 0 0 2 3 4 5 12 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 142 Independent Olympic Participants\u00a0(IOP) [IOP] 1 0 1 2 3 0 0 0 0 0 1 0 1 2 3 143 Zambia\u00a0(ZAM) [ZAM] 12 0 1 1 2 0 0 0 0 0 12 0 1 1 2 144 Zimbabwe\u00a0(ZIM) [ZIM] 12 3 4 1 8 1 0 0 0 0 13 3 4 1 8 145 Mixed team\u00a0(ZZX) [ZZX] 3 8 5 4 17 0 0 0 0 0 3 8 5 4 17 146 Totals 27 4809 4775 5130 14714 22 959 958 948 2865 49 5768 5733 6078 17579 <p>147 rows \u00d7 16 columns</p> <pre><code>only_gold = df.where(df['Gold']&gt;0)\nonly_gold.dropna(inplace=True)\nonly_gold.head()\n</code></pre> Unnamed: 0 # Summer Gold Silver Bronze Total # Winter Gold.1 Silver.1 Bronze.1 Total.1 # Games Gold.2 Silver.2 Bronze.2 Combined total 1 Algeria\u00a0(ALG) 12.0 5.0 2.0 8.0 15.0 3.0 0.0 0.0 0.0 0.0 15.0 5.0 2.0 8.0 15.0 2 Argentina\u00a0(ARG) 23.0 18.0 24.0 28.0 70.0 18.0 0.0 0.0 0.0 0.0 41.0 18.0 24.0 28.0 70.0 3 Armenia\u00a0(ARM) 5.0 1.0 2.0 9.0 12.0 6.0 0.0 0.0 0.0 0.0 11.0 1.0 2.0 9.0 12.0 4 Australasia\u00a0(ANZ) [ANZ] 2.0 3.0 4.0 5.0 12.0 0.0 0.0 0.0 0.0 0.0 2.0 3.0 4.0 5.0 12.0 5 Australia\u00a0(AUS) [AUS] [Z] 25.0 139.0 152.0 177.0 468.0 18.0 5.0 3.0 4.0 12.0 43.0 144.0 155.0 181.0 480.0 <pre><code>len(df.where((df['Gold']&gt;0) &amp; (df['Gold.1']&gt;0)).dropna()['Unnamed: 0'].unique())\n</code></pre> <pre>\n<code>37</code>\n</pre>"},{"location":"files/Introductie%20Pandas.html#pandas-series","title":"Pandas <code>Series</code>","text":""},{"location":"files/Introductie%20Pandas.html#querying-a-series-object","title":"Querying a <code>Series</code> object","text":""},{"location":"files/Introductie%20Pandas.html#the-dataframe-type","title":"The <code>DataFrame</code> type","text":""},{"location":"files/Introductie%20Pandas.html#data-loading","title":"Data loading","text":""},{"location":"files/Introductie%20Pandas.html#alles-in-een-list-comprehension","title":"Alles in een list-comprehension","text":""},{"location":"files/Introductie%20Pandas.html#querying-a-dataframe","title":"Querying a DataFrame","text":""},{"location":"files/Opdracht%20model-evaluatie.html","title":"Opdracht model evaluatie","text":"<p>download de open notebook hier.</p> <pre><code>from sklearn.datasets import load_breast_cancer\nimport numpy as np\n</code></pre> <pre><code># YOUR CODE HERE\n</code></pre> <p>Maak een Support Vector Classifier met de standaard-waarden voor alle parameters. Geef dit model mee aan <code>plot_learning_curve</code> die in <code>helpers.py</code> te vinden is. Behalve dit model verwacht die methode eveneens een titel, de <code>X</code> en de <code>y</code>. De volledige signature van die methode staat hieronder; bestudeer eventueel de code om de volledige implementatie te zien.</p> <pre><code>plot_learning_curve(\n    estimator,\n    title,\n    X,\n    y,\n    axes=None,\n    ylim=None,\n    cv=None,\n    n_jobs=None,\n    scoring=\"accuracy\",\n    train_sizes=np.linspace(0.1, 1.0, 5),\n)\n</code></pre> <pre><code>from sklearn.svm import SVC\nfrom helpers import plot_learning_curve\n# YOUR CODE HERE\n</code></pre> <p>Als het goed is, heb je nu hierboven drie grafieken staan. Bedenk op basis van deze visualisatie hoe goed of hoe slecht je vindt dat je classifier werkt.</p> <p>Experimenteer vervolgens met verschillende waarden voor de parameters van die <code>SVC</code>: verander de kernel en verhoog (als je kernel <code>poly</code> is) de <code>degree</code>.  Welke verschillen zie je in de visualisatis? Kun je op basis hiervan een voorstel doen voor de beste waarden voor die parameters?</p> <p>Maak gebruik van <code>train_test_split</code> om de data op te splitsen in tachtig procent trainingsdata en twintig procent testdata.</p> <p>Train een <code>SVC</code> op basis van de beste parameters die je hierboven hebt ge\u00efdentificeerd. Maak vervolgens een confusion matrix en een classificatie-raport op basis van de testdata met dit model. Maak tenslotte een ROC-curve van dit getrainde model. </p> <p>Geef op basis hiervan een analyse van de kwaliteit van het model en een advies over hoe het model eventueel te verbeteren zou zijn.</p> <pre><code>from sklearn.model_selection import train_test_split\n# YOUR CODE HERE\n</code></pre> <pre><code>from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n# YOUR CODE HERE\n</code></pre> <pre><code># Plot een confusion-matrix.\n# Maak gebruik van de klasse ConfusionMatrixDisplay die hierboven is ge\u00efmporteerd\n# YOUR CODE HERE\n</code></pre> <pre><code># Plot een ROC-curve.\n# Maak gebruik van de klasse RocCurveDisplay die hierboven is ge\u00efmporteerd\n# YOUR CODE HERE\n</code></pre> <pre><code>import pandas as pd\nimport numpy as np\n%matplotlib inline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# DataFrame om de gevonden metrieken per classifier in op te slaan.\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n\n# YOUR CODE HERE\n</code></pre> <p>In de cel hieronder wordt de variabele <code>result_table</code> gebruikt om de verschillende ROC's in \u00e9\u00e9n figuur te plotten. Je hoeft hiervoor niks te programmeren; als je de cel runt krijgt je als het goed is direct de juiste visualisatie. </p> <p>Kun je op basis van deze visualisatie een uitspraak doen over welk model de beste performance heeft voor deze dataset? </p> <pre><code>import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=f\"{i}, AUC={result_table.loc[i]['auc']:.3f}\")\n\nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"False Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()\n</code></pre>"},{"location":"files/Opdracht%20model-evaluatie.html#opdracht-model-evaluatie","title":"Opdracht model-evaluatie","text":""},{"location":"files/Opdracht%20model-evaluatie.html#opdracht-1","title":"Opdracht 1","text":"<p>Laad de borstkanker-dataset en maak gebruik van <code>DESCR</code> om een beeld te krijgen van de gegevens die in deze dataset zijn opgeslagen. zorg ervoor dat je de features in een variabele <code>X</code> krijgt en de targets in de variabele <code>y</code> (dit kan op minimaal twee manieren). Je hoeft voor deze opgave geen EDA te maken of de data helemaal op te schonen (mag natuurlijk wel).</p> <p>Je hoeft het niet allemaal in \u00e9\u00e9n cel te doen; voel je vrij om meer cellen aan te maken wanneer je dat wilt.</p>"},{"location":"files/Opdracht%20model-evaluatie.html#opdracht-2","title":"Opdracht 2","text":"<p>Maak en train nu verschillende andere typen classifiers (een aantal is hieronder gegeven, maar voel je vrij om een andere set te gebruiken). Let op: alle classifiers in sklearn implementeren dezelfde interface: maak hiervan gebruik in je realisatie.</p> <p>In de cel hieronder wordt een DataFrame <code>result_table</code> gedefinieerd. Het is de bedoeling dat je van alle classifiers die je gebruikt en traint de <code>fpr</code>, de <code>tpr</code> en de <code>auc</code> in dit DataFrame opslaat. Je kunt hiervoor gebruik maken van de sklearn-methoden <code>roc_curve</code> en <code>roc_auc_score</code>. </p>"},{"location":"files/intro%20notebook%20en%20sklearn.html","title":"Intro notebook en sklearn","text":"<p>Download de jupyter notebook hier.</p> <p>Zoals tijdens het theoriecollege is toegelicht, maken we vanaf deze week gebruik van Jupyter Notebooks, een feitelijke standaard voor het rapid prototyping van machine learning projecten. Het grote voordeel van notebooks is dat je de documentatie (in markdown) direct tussen je runbare code hebt staan. Hoewel oorspronkelijk ontwikkeld voor Python zijn er inmiddels voor de meeste talen kernels ontwikkeld, zodat je ook Java, Go of PHP in notebooks kunt schrijven.</p> <p>Een tweede stap die we nu gaan zetten in gebruik maken van een bibliotheek om het zware werk voor ons over te nemen: skikit learn. Tot nu toe schreven we alle code zelf, maar in het echt maak je gebruik van deze bibliotheek: die is sneller en makkelijker en stelt je in staat om je te richten op het maken en beoordelen van modellen in plaats van het goedlaten werken van feitelijk vrij triviale programmacode.</p> <p>E\u00e9n van de voordelen van sklearn is dat de meest gebruikte datasets standaard in deze bibliotheek zitten. Veel van de voorbeelden waar we de voorbije weken mee gewerkt hebben, zul je hierin terugvinden.</p> <p>In deze opgave maken we gebruik van de California Housing dataset. Run de volgende cel om de methode te importeren die deze dataset kan laden. Bestudeer de documentatie om te weten te komen wat er in deze dataset is opgeslagen en hoe je vervolgens de data daadwerkelijk laadt. </p> <pre><code># https://stackoverflow.com/a/49174340\n# Haal de onderstaande regel uit het commentaar als je SSL-errors krijgt:\n# ssl._create_default_https_context = ssl._create_unverified_context\nfrom sklearn.datasets import fetch_california_housing\nimport matplotlib.pyplot as plt\nimport numpy as np\n</code></pre> <p>Gebruik de onderstaande cel om de methode <code>fetch_california_housing</code> aan te roepen. Mocht je bij het laden SSL-errors krijgen, probeer dan de eerste regel in de bovenstaande cel uit het commentaar te halen en run die cel nogmaals. Gebruik <code>feature_names</code> om de namen van de eigenschappen van de dataset te weten te komen. Zorg ervoor dat je de data van het resultaat in een variabele <code>X</code> zet, en de target in een variabele <code>y</code>.</p> <pre><code># YOUR CODE HERE\n</code></pre> <p>Zoals altijd maken we ook een paar visualisaties van de data om een beeld te krijgen van wat er zoal in zit. We beginnen met een scatter-plot; alleen dit keer plotten we niet de \\(y\\)-vector tegen een eigenschap uit de \\(X\\)-matrix; omdat we weten dat we te maken hebben met geografische data, is het leuker om de lengte- en breedtegraden tegenover elkaar te plotten. Maar gebruik van <code>matplotlib.pyplot.scatter</code> om deze twee gegevens (Longitude en Latitude, respectievelijk) te plotten. Als je het goed hebt gedaan, kun je in de resulterende plot de kustlijn van Californi\u00eb herkennen.</p> <pre><code>#YOUR CODE HERE\n</code></pre> <p>Zoals je in de documentatie hebt gelezen, is de target-value de gemiddelde waarde van de huizen in die omgeving, uitgedrukt in honderdduizend dollar. Natuurlijk moeten we wat statistieken uit deze target-vector halen. Vul onderstaande cel aan, zodat de juiste waarden worden afgedrukt. Maar vervolgens gebruik van pyplot.hist om een histogram van deze data te plotten. Beargumenteer op basis van de statistische gegevens in hoeveel <code>bins</code> je deze histogram moet onderverdelen.</p> <pre><code>import statistics as st\n# YOUR CODE HERE\n# vervang '0' door de juiste code\nmin_value = 0\nmax_value = 0\nstdev = 0\ngemiddelde = 0\n\nprint ('==== DATA UIT DE TARGET-VECTOR ====')\nprint (f'Gemiddelde: {gemiddelde:&gt;10.2f}')\nprint (f'Minimum: {min_value:&gt;10.2f}')\nprint (f'Maximum: {max_value:&gt;10.2f}')\nprint (f'StdDev: {stdev:&gt;10.2f}')\n</code></pre> <p>Een belangrijke stap om een beeld te krijgen van de data in de set is door gebruik te maken van een histogram. E\u00e9n van de belangrijke vragen daarbij is in hoeveel <code>bins</code> je de data moet verdelen. Daarvoor zijn grofweg twee methoden: Sturge's Rule en Freedman-Diaconis rule. Bestudeer deze blog hierover maak beide histogrammen. Let op dat het aantal <code>bins</code> een geheel getal moet zijn.</p> <p>Als het goed is, kom je in het eerste geval op 16 <code>bins</code> en in het tweede geval op 46. Welke van beide histogrammen vind je beter en waarom?</p> <pre><code># histogram met Sturge's Rule\nm,n = X.shape\n\n# YOUR CODE HERE\n</code></pre> <pre><code># histogram met Freedman-Diaconis rule\nm,n = X.shape\n\n# YOUR CODE HERE\n</code></pre> <p>Nu gaan we de features van deze dataset gebruiken om een voorspelling te doen van de waarde van een huis. In week 1 hebben we de wiskunde daarvan helemaal uitgeprogrammeerd; nu maken we gebruik van 'sklearn.linear_model.linear_regression'.</p> <p>Verdeel de data in 20% testdata en 80% trainingsdata. Maak hiervoor gebruik van <code>train_test_split</code>. Laad de data opnieuw in met de parameter <code>return_X_y</code> op <code>True</code>, zodat je direct de features en de corresponderende targets hebt. Waarom is deze split ook al weer nodig?</p> <p>Gebruik vervolgens de methode <code>fit</code> om het model te trainen. </p> <pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n#YOUR CODE HERE\n</code></pre> <p>Gebruik nu de methode <code>predict</code> om op basis van de test-data een uitspraak te doen over hoe goed het model presteert. Gebruik hiervoor de methode <code>mean_square_error</code> uit <code>sklearn.metrics</code>. Hoe vind je dat het model presteert? Wat zou je kunnen doen om het model te verbeteren?</p> <pre><code>from sklearn.metrics import mean_squared_error\n#YOUR CODE HERE\n</code></pre> <p>Bestudeer tenslotte met behulp van het <code>coef_</code>-attribuut van het getrainde model om te weten te komen wat de formule is die het model gebruikt. Welke features zijn het belangrijkst en welke minder?</p> <pre><code>#YOUR CODE HERE\n</code></pre> <pre><code>\n</code></pre>"},{"location":"files/intro%20notebook%20en%20sklearn.html#introductie-jupyter-notebook-en-scikit-learn","title":"Introductie Jupyter Notebook en Scikit-learn","text":""},{"location":"files/intro%20notebook%20en%20sklearn.html#opdracht-1-data-laden-en-inspecteren","title":"Opdracht 1: data laden en inspecteren","text":""},{"location":"files/intro%20notebook%20en%20sklearn.html#opdracht-2-lineaire-regressie","title":"Opdracht 2: Lineaire regressie","text":""},{"location":"week1/index.html","title":"Week 1: Tools en technieken","text":"<ul> <li>Jupyter Noteboook</li> <li>hele cyclus doorlopen: data cleaning and preparation</li> <li>numpy, pandas, sklearn</li> </ul>"},{"location":"week2/index.html","title":"Week 2: Lineaire regressie","text":"<ul> <li>kostenfunctie en gradient descent</li> <li>lineaire regressie</li> </ul>"},{"location":"week2/inleveren.html","title":"Inleveren deel 1","text":"<ul> <li>ScikitLearn en California Housing (prep. en lin. regressie): https://hanze-hbo-ict.github.io/OpgavenML/files/intro%20notebook%20en%20sklearn.html</li> <li>Oude set week 1: https://hanze-hbo-ict.github.io/OpgavenML/week1.html</li> </ul>"},{"location":"week3/index.html","title":"Week 3: Logistische regressie en Neurale netwerken (1)","text":"<ul> <li>logistische regressie</li> <li>neurale netwerken 1</li> </ul>"},{"location":"week4/index.html","title":"Week 4: Neurale netwerken (2)","text":"<ul> <li>neurale netwerken 2</li> </ul>"},{"location":"week4/inleveren.html","title":"Inleveren deel 2","text":"<ul> <li>Losse opgave log. regressie: nog maken</li> <li>Oude set week 2: https://hanze-hbo-ict.github.io/OpgavenML/week2.html</li> </ul>"},{"location":"week5/index.html","title":"Week 5: Model-evaluatie","text":"<ul> <li>confusion matrix</li> <li>ROC / AUC</li> </ul>"},{"location":"week6/index.html","title":"Week 6: Andere modellen","text":"<ul> <li>SVC</li> <li>k-means en DBSCAN</li> <li>beslisbomen</li> <li>Random Forest</li> </ul>"},{"location":"week6/inleveren.html","title":"Inleveren deel 3","text":"<ul> <li>Oude set week 3: https://hanze-hbo-ict.github.io/OpgavenML/week3.html (minus opgave 3)</li> <li>Oude set week 4: https://hanze-hbo-ict.github.io/OpgavenML/files/Opdracht%20model-evaluatie.html</li> <li>Opgaven SVC en DBSCAN: heeft Bart, nog vergaren</li> </ul>"},{"location":"week7/index.html","title":"Week 7: Hyperparameter tuning","text":"<ul> <li>hyperparameter tuning</li> <li>GridSearchCV</li> <li>RandomizedSearchCV</li> <li>...and their halving counterparts</li> </ul>"},{"location":"week8/index.html","title":"Week 8: Geavanceerde onderwerpen","text":"<ul> <li>large language models</li> <li>dimensionaliteitsreductie en PCA</li> <li>ensemble learning</li> <li>informatie-entropie</li> </ul>"},{"location":"week8/inleveren.html","title":"Inleveren deel 4","text":"<ul> <li>Opgave over hyperparam tuning: nog ontwikkelen</li> <li>Vrije opgave over leuke dingen: nog ontwikkelen</li> </ul>"}]}